# Legal RAG System Configuration

database:
  host: "localhost"
  port: 5432
  name: "legal_rag"
  user: "postgres"
  password: ""  # Set via environment variable DB_PASSWORD
  min_connections: 2
  max_connections: 10

embedding:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384
  batch_size: 32
  device: "cpu"  # "cpu" or "cuda"

retrieval:
  hybrid:
    bm25_weight: 0.4
    vector_weight: 0.6
  bm25:
    k1: 1.5
    b: 0.75
  vector:
    similarity_threshold: 0.7
    top_k: 20
  rerank:
    enabled: false
    model: "cross-encoder/ms-marco-MiniLM-L-6-v2"

chunking:
  chunk_size: 512  # tokens
  chunk_overlap: 50  # tokens
  min_chunk_size: 100  # tokens
  max_chunk_size: 1024  # tokens

ner:
  model: "spaCy"  # "spaCy" or "transformers"
  model_name: "en_core_web_sm"  # or custom fine-tuned model
  entity_types:
    - PERSON
    - CASE_NUMBER
    - LEGAL_SECTION
    - COURT
    - DATE
    - PENALTY
    - LEGAL_TERM
    - STATUTE
    - ORGANIZATION

llm:
  provider: "openai"  # "openai", "anthropic", "huggingface", "local"
  model: "gpt-4"
  temperature: 0.3
  max_tokens: 2000
  api_key: ""  # Set via environment variable

summarization:
  max_context_length: 4000  # tokens
  summary_types:
    - extractive
    - abstractive
    - hybrid
  prompt_template: "legal_summary"

ingestion:
  batch_size: 100
  max_workers: 4
  pdf_extraction:
    library: "pdfplumber"  # "pdfplumber", "pypdf", "PyPDF2"
    max_pages: null  # null for all pages

paths:
  data_dir: "./data"
  judgments_dir: "./judgments_*"
  criminal_dir: "./criminal_*"
  datasets_dir: "./datasets"
  output_dir: "./output"
  cache_dir: "./cache"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "legal_rag.log"

evaluation:
  metrics:
    - rouge_l
    - rouge_1
    - rouge_2
    - bleu
    - bertscore
  test_set_size: 100
  k_values: [5, 10, 20]
